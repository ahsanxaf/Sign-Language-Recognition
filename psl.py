# -*- coding: utf-8 -*-
"""PSL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V1DiBO74WisX4doryb0FSHZkxu-zbcgr
"""

import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt
import os
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv3D, MaxPool3D, Dropout
from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout
from tensorflow.keras.optimizers import SGD
from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.preprocessing.image import ImageDataGenerator

directory = r'C:\Users\AHSAN FAROOQ\OneDrive\Desktop\KINECT dataset-20211226T074715Z-001\KINECT dataset'
CATEGORIES = ['Allah Hafiz', 'ap kese hain', 'Apka naam kiyahai']

data = []
labels = []
for category in CATEGORIES:
    folder = os.path.join(directory, category)
    label = CATEGORIES.index(category)
    print(folder)
    for frame in os.listdir(folder):
        frm_path = os.path.join(folder, frame)
        cap = cv.VideoCapture(frm_path)
        video = []
        while cap.isOpened():
            ret, frames = cap.read()
            if ret == True:
                video.append(frames)
            else:
                break
        if len(video) > 30:
            for i in range(len(video)):
                video[i] = cv.resize(video[i], (200, 200))
                video[i] = cv.cvtColor(video[i], cv.COLOR_BGR2GRAY)
#                 video[i] = video[i].astype(np.uint8)
#                 print (video[i].max(), video[i].min())
                _, video[i] = cv.threshold(video[i], 175, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)
            rem = len(video) % 30
            video = video[int(rem/2): -(int(rem/2))]
            if len(video) % 2 != 0:
                video = video[1:]
            NumberOfSamples = int(len(video)/30)
            for i in range(NumberOfSamples):
                sample = np.array(video[i*30: ((i+1)*30)])
                features = []
                for i in range (len(sample)):
                    _, th = cv.threshold(sample[i], 175, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)
                    frame_features = list(th)
                    features.append(frame_features)
                data.append(features)
                labels.append(category)

  
print ("dataset ",np.array(data).shape)



print(data.shape)

print(labels)

from sklearn import preprocessing
le = preprocessing.LabelEncoder().fit(labels)
labels = le.transform(labels)

X = np.array(data)
y = np.array(labels)

X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=1)

X_train = X_train/255
X_test = X_test/255

print(X_train.shape)

print(X_train.shape)

X_train=X_train.reshape(185, 30, 200, 200, 1)

opt = SGD(lr=0.0001)
#defining model
model=Sequential()
#adding convolution layer
model.add(Conv3D(32,3,activation='relu',input_shape=(30, 200, 200, 1)))
#adding pooling layer
model.add(MaxPool3D(2,2))

#adding convolution layer
model.add(Conv3D(32,3,activation='relu'))
#adding pooling layer
model.add(MaxPool3D(2,2))

#adding convolution layer
model.add(Conv3D(32,3,activation='relu'))
#adding pooling layer
model.add(MaxPool3D(2,2))

#adding fully connected layer
model.add(Flatten())
model.add(Dense(100,activation='relu'))
#adding output layer
model.add(Dense(10,activation='softmax'))
#compiling the model
model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])
#fitting the model
history=model.fit(X_train,Y_train, batch_size=4, epochs=150)

model.summary()

